
# vLLM Benchmarking with OpenVINO

This explains the process of benchmarking vLLM with OpenVINO.
For additional information, please refer to the following resources:
- OpenVINO [GenAI Pipeline Repository](https://github.com/openvinotoolkit/openvino.genai)
- OpenVINO [Large Language Model Inference Guide](https://docs.openvino.ai/2024/learn-openvino/llm_inference_guide.html)
- OpenVINO [Benchmarking script for vLLM](https://docs.vllm.ai/en/latest/getting_started/openvino-installation.html)
  

#### Step 0: Prepare Environment


#### Step 1: Setup environment

#### Step 2:  Setup OpenVINO LLM benchmarking repo


#### Step 3: Login into huggingface if you need to use non public models.


#### Step 4:  Convert the model to OpenVINO format. 

#### Step 5: Performance benchmarking:

